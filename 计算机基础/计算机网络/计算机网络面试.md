## 计算机网络体系结构

- 应用层：常见协议：
  - FTP(21端口)：文件传输协议
  - SSH(22端口)：远程登陆
  - TELNET(23端口)：远程登录
  - SMTP(25端口)：发送邮件
  - POP3(110端口)：接收邮件
  - HTTP(80端口)：超文本传输协议
  - DNS(53端口)：运行在UDP上，域名解析服务
- 传输层：TCP/UDP
- 网络层：IP、ARP、NAT、RIP...

### GET与POST的区别？

1. GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；
2. GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；
3. 请求形式上：GET请求的数据附在==URL之后==，在HTTP请求头中；POST请求的数据在==请求体==中；
4. 安全性：GET请求因为是幂等的，所以可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；
5. GET只允许ASCII字符（**URL 规定只能支持 ASCII**），POST对数据类型没有要求，也允许二进制数据；
6. GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制

> ==注意：Get请求也可以用来 新增和删除数据，Post请求也可以用来获取数据==

### Session与Cookie的区别？

- **保存的位置不同：**Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案
- **大小限制不同**：\```cookie`最多可以存放`4k`大小的内容，`session`则没有限制。
- **内容不同：** cookie只能存储字符串，而`session`存储结构类似于`hashtable`的结构，可以存放任何类型。
- Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。

`cookie的session的应用场景：`cookie可以用来保存用户的登陆信息，如果删除cookie则下一次用户仍需要重新登录
[session](https://so.csdn.net/so/search?q=session&spm=1001.2101.3001.7020)就类似于我们拿到钥匙去开锁，拿到的就是我们个人的信息，一般我们可以在session中存放个人的信息或者购物车的信息。

**session和cookie的弊端：**

- cookie的大小受限制，cookie不安全，如果用户禁用cookie则无法使用cookie。
- 如果过多的依赖session，当很多用户同时登陆的时候，此时服务器压力过大。sessionId存放在cookie中，此时如果对于一些浏览器不支持cookie，此时还需要改写代码，将sessionID放到url中，**也是不安全。**

## 域名解析的工作流程

所以域名的层级关系类似一个树状结构：

- 根 DNS 服务器（.）
- 顶级域 DNS 服务器（.com）
- 权威 DNS 服务器（server.com）

![image-20220601155045569](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220601155045569.png)

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” **根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。**
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

### 从输入网址到获得页面的过程 (越详细越好)？

> 更详细版本：https://xiaolincoding.com/network/1_base/what_happen_url.html

1. 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；
   1. **向本地域名服务器查询属于递归查询，向根域名和顶级域名服务器查询属于迭代查询**
2. 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；
3. TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；
4. 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；
5. 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；
6. 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。

> 在传输过程中 MAC头部中的MAC地址是会一直变化的，而IP头中源IP和目的IP是不变的
>
> 

## 在浏览器输入 URL 并回车后，如果页面迟迟没有出现，怎么去排查问题

1. 先确定是服务端的问题，还是客户端的问题。先确认浏览器是否可以访问其他网站，如果不可以，说明客户端网络自身的问题，然后检查客户端网络配置（连接wifi正不正常，有没有插网线）；如果可以正常其他网页，说明客户端网络是可以正常上网的。

2. 如果客户端网络没问题，就抓包确认 DNS 是否解析出了 IP 地址，如果没有解析出来，说明域名写错了，如果解析出了 IP 地址，抓包确认有没有和服务端建立三次握手，如果能成功建立三次握手，并且发出了 HTTP 请求，但是就是没有显示页面，可以查看服务端返回的响应码：

3. - 如果是404错误码，检查输入的url是否正确；
   - 如果是500，说明服务器此时有问题；
   - 如果是200，F12看看前端代码有问题导致浏览器没有渲染出页面。

4. 如果客户端网络是正常的，但是访问速度很慢，导致很久才显示出来。这时候要看客户端的网口流量是否太大的了，导致tcp发生丢包之类的问题。

> 总之就是一层一层有没有插网线，网络配置是否正确、DNS有没有解析出 IP地址、TCP有没有三次握手、HTTP返回的响应码是什么。

# 传输层

## TCP/UDP



### 三次握手 

<img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220530122035718.png" alt="image-20220530122035718" style="zoom:50%;" />

> - \1. 服务器 listen 时，计算了全/半连接队列的长度，还申请了相关内存并初始化。==半连接队列是哈希表（为了能快速查找），全连接队列是链表，每次从链表头拿即可==
> - \2. 客户端 connect 时，把本地 socket 状态设置成了 TCP_SYN_SENT，选则一个可用的端口，发出 SYN 握手请求并启动重传定时器。
> - \3. 服务器响应 ack 时，会判断下接收队列是否满了，满的话可能会丢弃该请求。否则发出 synack，申请 request_sock 添加到半连接队列中，同时启动定时器。
> - \4. 客户端响应 synack 时，==清除了 connect 时设置的重传定时器==，把当前 socket 状态设置为 ESTABLISHED，==开启保活计时器==后发出第三次握手的 ack 确认。
> - \5. 服务器响应 ack 时，把对应半连接对象删除，创建了新的 sock 后加入到全连接 队列中，最后将新连接状态设置为 ESTABLISHED。
> - \6. accept 从已经建立好的全连接队列中取出一个返回给用户进程。
> - 



- 第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；  **选取一个空闲的端口**
- 第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1                                                                                                                
- 第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。  **会检查ACK确认的序号，是否为上次发出了，而不是之前过期的**

  #### 1. 可以使用两次握手建立连接吗？

​	接下来，以三个方面分析三次握手的原因：

1. **三次握手才可以阻止重复历史连接的初始化（主要原因）**
2. **三次握手才可以同步双方的初始序列号**
3. **三次握手才可以避免资源浪费**（类似1）

**具体如下**

1. 首先，可能会出现**已失效的连接请求报文段又传到了服务器端**。

   client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。

   - 如果是两次握手的话，直接连接就建立了
   - 三次握手的话，**客户端可以根据 服务端确认的ACK序列号判断出，这是过期序列号或超时**，那么客户端就会发送 `RST` 报文给服务端，表示中止这一次连接。
   - ![image-20220513200459203](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220513200459203.png)

2. ***原因二：同步双方初始序列号***

   TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

   - **接收方可以去除重复的数据；**
   - **接收方可以根据数据包的序列号按序接收；**
   - 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

   可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

#### 2.初始序列号是什么？

TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

> **第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，



#### 3. 为什么 TCP 每次 建立连接时，初始化序列号都要不一样呢？

主要原因是为了防止历史报文被下一个相同四元组的连接接收。



#### 4. 什么情况下SYN报文会被丢弃掉

-  tcp_tw_recycle
-  半连接队列满了
-  全连接队列满了·

#### 5. 最大连接数量 

**只需要四元组不同即可**  

==一个端口可以用于建立多个连接==

所以最大连接数远远不止 65536 但是注意Linux 对最大文件描述符有限制

**增加连接数的方式：**

- 可以给客户端配置多个网卡，也就是同一台机器有多个IP
- 修改最大的文件描述符限制

#### 一个TCP连接的耗时

- 正常情况下建立一个TCP连接只需要==一个RTT左右==（对于客户端而言 第三次握手的ACK发出就认为建立完成），其中CPU的耗时相对而言忽略不计，一个系统调用的耗时大于几微秒

#### 内存

一个空的establish连接需要消耗3kb左右的内存

#### syn_cookie的工作方式

> 可以不使用半连接队列

- 服务器收到syn请求(第一次握手)后，会根据当前状态计算出一个cookie值。放在syn+ack报文(第二次握手)中发出。
- 当客户端返回ack报文(第三次握手)时会再次带上这个cookie值。服务端取出这个值进行验证。如果合法就认为连接建立成功。**加入全连接队列中。**

#### 第一次握手丢失

客户端会重传，且**每次超时的时间是上一次的 2 倍**。

当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。

所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。

#### 第二次握手丢失了

- 客户端和服务端都会重传

- 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 `tcp_syn_retries`内核参数决定；
- 服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定。

#### 第三次握手丢失了

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，**直到收到第三次握手，或者达到最大重传次数。**

==注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。==



#### syn攻击

> 占满半连接队列

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。

##### 方法:

​	开启syn_cookie



### 四次挥手？

<img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220728095237.png" alt="image-20220728095237243" style="zoom:50%;" />

- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；**进入FIN_WAIT_1状态；**
- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；**进入CLOSE_WAIT状态**。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。
- 第三次挥手：Server将FIN置1，发送一个序列号给Client；**进入LAST_ACK状态**；
- 第四次挥手：Client收到服务器的FIN后，**进入TIME_WAIT状态；**接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。

#### 1.为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

- 因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

#### 2. 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

- 客户端没有收到ACK确认，会重新发送FIN请求。

#### 3. time_wait状态的意义

- **防止历史连接中的数据，被后面相同四元组的连接错误的接收；**
  - `MSL` **报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
  - 如果不等待    可能出现上一个连接中的报文被**网络延迟了**，接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 `SEQ = 301` 这时抵达了客户端，而且该**数据报文的序列号刚好在客户端接收窗口内**，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，**这样就产生数据错乱等严重的问题**。
- **保证「被动关闭连接」的一方，能被正确的关闭；**
  - 第四次挥手时，主动方 发送给 接收方 的**最后一次ACK**有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。==如果Server没有收到ACK，就会重发FIN，==如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。



### TCP如何实现流量控制？

**TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区**

> 接收方根据它的缓冲区，可以计算出后续能够接收多少字节的报文，这个数字叫做==接收窗口==。当内核接收到报文时，必须用缓冲区存放它们，这样剩余缓冲区空间变小，接收窗口也就变小了；当进程调用 read 函数后，数据被读入了用户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报文，接收窗口就会变大。

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。**接收方会维护一个接收窗口** receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，**只有当发送方发送并收到确认之后，才能将发送窗口右移**。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

##### 什么是零窗口（接收窗口为0时会怎样）？

如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是**会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包**，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

### TCP的拥塞控制是怎么实现的？

拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**

1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍

2. 拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**

3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

> - `cwnd = cwnd/2` ，也就是设置为原来的一半;
>
> - `ssthresh = cwnd`; 注意此时的cwnd 已经是阻塞时的一半了

4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。
   也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。

> cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；

> 流量控制和拥塞控制的区别？
>
> - 流量控制保证发送的数据不超过==接收方的承受范围==
> - 拥塞控制保证发送的数据不超过==网络的承受能力==





### TCP如何最大利用带宽？（如何确定最大传输速度？）

在前面我们知道了 TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力。其中，窗口大小由内核缓冲区大小决定。如果缓冲区与网络传输能力匹配，那么缓冲区的利用率就达到了最大化。

问题来了，如何计算网络的传输能力呢？

相信大家都知道网络是有「带宽」限制的，带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:

- 带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；
- 缓冲区单位是字节，当网络速度乘以时间才能得到字节数；

这里需要说一个概念，就是带宽时延积，它决定网络中飞行报文的大小，它的计算方式：

![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/44.jpg)

比如最大带宽是 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节。

这个 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为 BDP，Bandwidth Delay Product）。同时，这 1MB 也表示「飞行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1 MB，就会导致网络过载，容易丢包。

**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。**

发送缓冲区与带宽时延积的关系：

- 如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；
- 如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。

所以，发送缓冲区的大小最好是往带宽时延积靠近。

### TCP校验和

> 不能完全保证可靠传输，有可能前后刚好交换  因为只是一个简单的累加校验    A+B= B+A

检验和计算过程（以TCP校验为例）

​    TCP首部校验和计算三部分：TCP首部+TCP数据+TCP伪首部。

发送端： 

​    首先，把伪首部、TCP报头、TCP数据分为16位的字，如果总长度为奇数个字节，则在最后增添一个位都为0的字节。

​    把TCP报头中的校验和字段置为0。

​    其次，用反码相加法（对每16bit进行二进制反码求和）累加所有的16位字（进位也要累加，进位则将高位叠加到低位）。

​    最后，将上述结果作为TCP的校验和，存在检验和字段中。

接收端：

​    同样利用反码求和，高位叠加到低位， 如计算结果的16位中每一位都为1，则正确，否则说明发生错误。  

![image-20220608110258332](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//imgs/image-20220608110258332.png)



### **TCP 和 UDP 区别：**

***1. 连接***

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

***2. 服务对象***

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

***3. 可靠性***

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

***4. 拥塞控制、流量控制***

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

***5. 首部开销***

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

***6. 传输方式***

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

***7. 分片不同***

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

##### 什么时候选择TCP，什么时候选UDP？

- ​	对某些实时性要求比较高的情况，选择UDP，比如游戏，媒体通信，实时视频流（直播），即使出现传输错误也可以容忍；其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失

##### HTTP可以使用UDP吗？

- HTTP不可以使用UDP，HTTP需要基于可靠的传输协议，而UDP不可靠   
- 注：**http 3.0 使用udp实现** https://zh.wikipedia.org/wiki/HTTP/3

##### 面向连接和无连接的区别

- 无连接的网络服务（数据报服务）-- 面向连接的网络服务（虚电路服务）

- 虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；

- 数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；

### TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出

### 使用UDP怎么实现可靠传输

**传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。实现确认机制、重传机制、窗口确认机制。**

### TCP Fast Open

TCP 三次握手的延迟被 TCP Fast Open （快速打开）这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。

![常规 HTTP 请求 与 Fast  Open HTTP 请求](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//imgs45.jpg)



**过程如下：**

- 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；

TCP Fast Open 这个特性是不错，但是它需要服务端和客户端的操作系统同时支持才能体验到，而 TCP Fast Open 是在 2013 年提出的，所以市面上依然有很多老式的操作系统不支持，而升级操作系统是很麻烦的事情，因此 TCP Fast Open 很难被普及开来。

> 还有一点，针对 HTTPS 来说，TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。



### tcp常见问题

#### 1. 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

我们先来认识下 MTU 和 MSS

![image-20220513202131393](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220513202131393.png)

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；

如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？

当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。

这看起来井然有序，但这存在隐患的，**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。

因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。

因此，可以得知由 IP 层进行分片传输，是非常没有效率的。

所以，为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。

![image-20220513203820275](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220513203820275.png)

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

#### 2. SYN攻击

这里给出几种防御 SYN 攻击的方法：

- 增大半连接队列；
- 开启 tcp_syncookies 功能   不经过半连接队列就可建立连接
- 减少 SYN+ACK 重传次数

#### 3. TCP粘包 问题

因为tcp是面向字节流的，所以消息没有边界   

当两个消息的某个部分内容被分到**同一个 TCP 报文**时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。

#### 如何解决

一般有三种方式分包的方式：

- **固定长度的消息；**
- **特殊字符作为边界；**
- **自定义消息结构**：我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

#### 4. 为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？

主要原因是为了防止历史报文被下一个相同四元组的连接接收。

如果每次都是通过四次挥手结束的连接，因为会time-wait 等待2msl  不存在上述问题，但是不能保证每次都能够通过四次挥手断开连接

#### 5. TCP收到乱序包，如何处理

「**在 FIN_WAIT_2 状态下，是如何处理收到的乱序到 FIN 报文，然后 TCP 连接又是什么时候才进入到 TIME_WAIT 状态?**」

>**在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。**
>
>**等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。**

![image-20220521210306590](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220521210306590.png)

图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，**其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到**，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的

#### 6. TCP keepalive 机制具体是怎么样的？

这个机制的原理是这样的：

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

#### 7.拔掉网线后， 原本的 TCP 连接还存在吗？

- **拔掉网线后，有数据传输**
  - 拔掉网线会，进行超时重传，如果在重传的过程中接上网线了，tcp连接会继续存在
  - **如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去**，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。
- **拔掉网线后，无数据传输**
  - 如果**没有开启** TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。
  - 而如果**开启**了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文，去判定对端是否正常工作

#### 8、tcp_tw_reuse 是什么？

在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768~61000 ，也可以通过如下参数设置指定范围：

```text
 net.ipv4.ip_local_port_range
```

那么，如果如果主动关闭连接方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。

不过，Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：

- net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**内核会随机找一个 TIME_WAIT 状态超过 1 秒的连接给新的连接复用**，所以该选项只适用于连接发起方。
- net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收，该参数在 **NAT 的网络下是不安全的！**

#### 9.开启tcp_tw_reuse有什么危害

相当于跳过time-wait或者说把time-wait时间设置为很短

#### 10.tcp连接，一段断电和进程崩溃的区别

- 一端断电 **类似拔掉网线**

- 进程崩溃

我自己做了实验，使用 kill -9 来模拟进程崩溃的情况，发现**在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手**。

所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。

#### 11. TCP的keep-Alive和HTTP的keep-Alive的区别

- **HTTP 的 Keep-Alive 也叫 HTTP 长连接**，该功能是由==「应用程序」==实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。
- **TCP 的 Keepalive 也叫 TCP 保活机制**，该功能是由==「内核」==实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

#### 12. TCP还存在什么问题

- 建立过程要三次握手,存在一定延时  (使用TCP Fast Open可以解决  使第二次建立连接更快)
- **队头阻塞问题**     TCP 层必须保证收到的字节数据是完整且有序的,当有一个数据包没有达到的时候就会出现阻塞,等到这个重传到,窗口才往后滑动
- **网络迁移需要重新建立 TCP 连接** 基于 TCP 传输协议的 HTTP 协议，由于是通过**四元组**（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接, 那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

> ##### TCP Fast Open
>
> 第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。
>
> 之后，如果客户端再次向服务器建立连接时支持 TCP Fast Open 的服务器会**对收到 Cookie 进行校验**：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序

![开启 TCP Fast Open 功能](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220712200338.jpeg)

#### 13.QUIC协议是如何基于UDP解决TCP的问题的

-  HTTP2基于TCP就算收到了 但是如果**不是有序的 就会放到乱序的队列中**，等待前面全部到达才能继续接收这就是**队头阻塞的主要原因**  	基于UDP 不保证数据的有序性，但是保证可靠性，丢失会重传 所以即使有数据丢失也只会影响一个流
- 直接通过==连接ID==建立连接更快
- 不是通过四元组建立连接  ,即使网络变换 也不需要连接迁移

#### 14.TCP 四元组可以唯一的确定一个连接，四元组包括如下：

- 源地址

- 源端口

- 目的地址

- 目的端口

- > 四元组中只要一个元素不一样，就是不同的连接

# 应用层

## HTTP

### HTTP的组成

#### 请求包

**请求行,请求头,空行（必须有的）,请求体**

![image-20220730205647401](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220730205647.png)

- **请求行**

  - Method 
  - Request-URI 
  - HTTP-version 

- **请求头**（键值对的形式）

  - 请求头的格式为键值对。一般常见的请求头如下：

  - User-Agent:PostmanRuntime/7.26.8     表示产生请求的客户端程序

  - Accept:*/*     表示可接受的响应的类型为全部类型


  - Accept-Language:zh     表示可接受的响应的语言为中文


  - Accept-Encoding:gzip     表示客户端请求的压缩方式


  - Cookie:value     值由登陆之后服务端下发


  - token:value     值由登陆之后服务端下发

- **请求体**（body）

  - body就是post要传输的数据

#### 响应包

![image-20220730212715631](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220730212715.png)

### HTTP的长连接和短连接?

HTTP的长连接和短连接本质上是**TCP长连接和短连接**。HTTP属于应用层协议.

*短连接:浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。*

**长连接:**当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

TCP短连接: client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起 close操作.短连接一般只会在 client/server间传递一次读写操作

TCP长连接: client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

### HTTP和HTTPS有什么区别？

1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；
2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了**加密和认证机制**，更加安全；
3. HTTPS由于加密解密会带来更大的CPU和内存开销；
4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买

**HTTP存在三个风险**

- **窃听风险**
- **篡改风险**
- **冒充风险**

**TLS 协议是如何解决 HTTP 的风险的呢？**

- *信息加密*： HTTP 交互信息是被加密的，第三方就无法被窃取；
- *校验机制*：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示；
- *身份证书*：证明淘宝是真的淘宝网；

### Https的连接过程？

> TLS1.2 需要4 次握手
>
> TLS1.3 只要2次握手

#### 第一次握手

- 客户端首先会发一个「**Client Hello**」消息 ，消息里面有==客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（\*Client Random\*）**==，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一

#### 第二次握手

- 当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从客户端提供的密码套件列表中选择一个密码套件，以及生成**随机数（Server Random）**，
- 服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。
  - 密码套件的基本的形式是「**密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法**」

#### 第三次握手

- 客户端首先对证书进行验证
- 客户端就会生成一个新的**随机数，用服务器的 RSA 公钥加密该随机数，通过「Change Cipher Key Exchange**」消息传给服务端。于是，双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。
- 然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个摘要，再用==会话密钥（master secret）加密==一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。

#### 第四次握手

- 服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

最后，就用「会话密钥」加解密 HTTP 请求和响应了。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

> 总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。
>
> ![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/https)



### https的单向认证和双向认证

- 单向验证过程中，客户端会验证自己访问的服务器，服务器对来访的客户端身份不做任何限制。如果服务器需要限制客户端的身份，则可以选择开启服务端验证，这就是双向验证。从这个过程中我们不难发现，**使用单向验证还是双向验证****，是服务器决定的。**
- **服务器默认都是使用单向验证**
- 双向认证还是只有四步，但是在第二步服务端会向客户端要客户端的证书，第三步客户端会把自己的证书发给服务端



### 摘要算法的作用

**摘要算法**用来实现**完整性**，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，**解决了篡改的风险。**

![校验完整性](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/21-%E6%A01%A1%E9%AA%8C%E5%AE%8C%E6%95%B4%E6%80%A7.png)

客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。



### 如何让自己的请求走HTTPs请求

##### 输入 [www.baidu.com，怎么变成](http://www.baidu.xn--com%2C-yj5fs80afjwtvd/) [https://www.baidu.com](https://www.baidu.com/) 的，怎么确定用HTTP还是HTTPS？



浏览器默认的端口一直都是80端口，也就是说默认情况下它是走的http协议，那么为了让它通过https协议来访网站，服务器实际上做了这些事情。

- 使用http协议并监听80端口，等待浏览器的访问.

- 在监听的80端口上设置url重定向，指向监听端口为443的https协议的网站

- 通过这样一种方式就可以实现网站地址的重定向了。

- 但并不是每次都会重定向的，利用==HSTS机制==返回的302报文中有这样一条`Strict-Transport-Security: max-age=31536000\r\n`

  其含义是强制浏览器在max-age到期之前，把所有的 [www.baidu.com，自动转换成[https://www.baidu.com](https://www.baidu.com/) 

  是==浏览器实现的url转换，==不用每次访问两次服务器，一步到位。这样避免了302跳转80->443的中间人劫持的问题。所以之后每次访问就不会出现302了，只有第一次会出现。



- https://blog.csdn.net/gui951753/article/details/82227800

  一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。 ==解决方法是引入HSTS机制==，用户浏览器在访问站点的时候强制使用HTTPS。
  
  


### 什么是对称加密、非对称加密？区别是什么？

- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4
- 非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA
- 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）

### 数字签名、报文摘要的原理

- 发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。
- **摘要算法:MD5、SHA**



### 如何保证公钥不被篡改和信任度？

所以这里就需要借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

#### 数字证书签发和验证流程

如下图图所示，为数字证书签发和验证流程：

![image-20220504214315752](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504214315752.png)

**CA 签发证书的过程**，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- ==然后 CA 会使用自己的私钥将该 Hash 值加密，==生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

**客户端校验服务端的数字证书的过程**，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。





### HTTP请求有哪些常见状态码？

1. 2xx状态码：操作成功。200 OK
2. 3xx状态码：重定向。301 永久重定向；302暂时重定向
3. 4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden 资源不可用禁止访问；404 Not Found 资源未找到；405  Method Not Allowed  请求方法不适用
4. 5xx状态码：服务端错误。500服务器内部错误；501服务不可用   503 服务器忙



### HTTP1.0 、1.1 、 2.0 、3.0的区别

#### 1.0

- 使用的是短连接  每次请求都要建立一个新的连接

#### 1.1

##### 相比1.0的提升

- 使用 TCP **长连接**的方式改善了 HTTP/1.0 短连接造成的性能开销。
- **支持管道（pipeline）网络传输**，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

##### 但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应

#### 2.0

- **头部压缩**：HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。

  这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

- **二进制分帧**：http2.0之所以能够突破http1.X标准的性能限制，**改进传输性能，实现低延迟和高吞吐量**，就是因为其新增了二进制分帧层。

- **多路复用**：HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。

  <img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504200847472.png" alt="image-20220504200847472" style="zoom: 80%;" />

- **数据流：** 在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流（`Stream`）。每个数据流都标记着一个独一无二的编号（Stream ID），**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息

- **服务端推送**：HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息，比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：

![image-20220504201250124](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504201250124.png)

##### HTTP2.0存在的问题

HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

- **队头阻塞**；
- **TCP 与 TLS 的握手时延迟**；基于https，需要经过 TCP 三次握手和 TLS 四次握手
- **网络迁移需要重新连接；**

#### HTTP/3

HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，==还基于 UDP 协议在「应用层」实现了 **QUIC 协议**，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了==，所以不用担心数据包丢失的问题。

QUIC 协议的优点有很多，这里举例几个，比如：

- **无队头阻塞；**
  - HTTP/2 的队头阻塞问题见上， ==**虽然后序的 数据到达了 接收端**，但是TCP需要保证有序性才将数据 提交给应用层==
  - HTTP/3 因为使用的是基于UDP的在传输层不保证可靠传输，所以尽管有数据丢失，应用层可以拿到其他已经到达的数据
- **更快的连接建立；**  首次建立只需要1RTT ，第二次建立客户端缓存了ServerConfig，0RTT  HTTP2及之前 TCP和TLS层是分开的， HTTP3 使用Quic协议没有分开，可以同时
- **连接迁移**



> HTTP1.1 的队头阻塞 ：必须按顺序处理请求 一个阻塞导致后面阻塞
>
> HTTP2 的队头阻塞 ： 使用多路复用可以 按优先级处理，但是一旦确定之后，TCP一定会保证可靠有序传输，有包丢失会导致后序阻塞 (==HTTP2 只解决了 应用层的队头阻塞，没有解决TCP的队头阻塞==)
>
> HTTP3：使用UDP在传输层不保证可靠传输，虽然有数据丢失，应用层也可以拿到数据，再判断，再重传

### HTTP请求包含什么

**请求行,请求头,空行（必须有的）,请求体**

***请求行**包含三个内容* method + request-URI + http-version

请求头包含:

-  	User-Agent：产生请求的浏览器类型。
- ​      Accept：客户端可识别的内容类型列表。
- ​      Host：主机地址





###  有TCP了，为什么还要HTTPS

- TCP这能保证从运输层到运输层之间的可靠传输，HTTPS的TLS则是保证在应用层的数据可靠
- TCP校验和 无法100%保证数据的可靠，如果前后两个16bit的数据刚好交换了（虽然概率极低），校验和就检验不出
- TCP的校验和是谁都可以生成的，假设使用HTTP协议，因为是明文传输在传输过程中，被中间节点劫持，完全可以自己生成不同的HTTP，**做对应的TCP校验和加在TCP首部中**，传输到接收端之后，TCP校验和不出检测出问题，但是应用层得到的不是自己想要的，**HTTPS传输的是密文**，通过密钥加密其他节点看不到。



## 浏览器缓存机制

#### **强制缓存**

> **强缓存**指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

使用 Cache-Control 来实现强缓存。具体的实现流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。



#### 协商缓存

> **协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**。

当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。

![image-20220504204503086](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504204503086.png)

![image-20220504204515982](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504204515982.png)

协商缓存可以基于两种头部来实现。

第一种：请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现，

第二种：请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段，

第一种实现方式是**基于时间实现**的，第二种实现方式是**基于一个唯一标识实现**的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。

![image-20220504204950466](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220504204950466.png)



**使用 ETag 字段实现的协商缓存的过程如下；**

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；

- 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期，如果没有过期，则直接使用本地缓存；如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；

- 服务器再次收到请求后，

  ==会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：==

  - **如果值相等，则返回 304 Not Modified，不会返回资源**；
  - 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；

- 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源







# 网络层

### 什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？

每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。

<details style="box-sizing: border-box; display: block; margin-top: 0px; margin-bottom: 16px;"><summary style="box-sizing: border-box; display: list-item; cursor: pointer;">优缺点</summary></details>

- 

### IP地址的分类？

[![IP address](https://github.com/wolverinn/Waking-Up/raw/master/_v_images/20191201085151639_2895.png)](https://github.com/wolverinn/Waking-Up/blob/master/_v_images/20191201085151639_2895.png)

路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。

### 什么叫划分子网？

从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：**网络号和子网号都为1，主机号为0；**数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。

## 什么是ARP协议 (Address Resolution Protocol)？

**ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。

### 工作过程

1.首先，每个主机都会在自己的ARP缓冲区建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系

2.当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，直接发送数据，如果没有，**向本网段**的所有主机发送ARP数据包，该数据包包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址

3.当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址。如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中。如果已经存在，则覆盖，然后将自己的MAC地址写入到ARP响应包中，告诉源主机自己是它想要找的MAC地址。

4.源主机收到ARP响应包后，将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

> 如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。
>



## 什么是NAT (Network Address Translation, 网络地址转换)？

==私网到公网的转换==

用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。

https://blog.csdn.net/gui951753/article/details/79593307





**百度发送的数据目的地址是局域网的公有IP，局域网的服务器收到百度的数据后如何确认发送到是局域网内的那一台主机？是不是百度发送的数据包目的地址里包括访问百度的那台主机的MAC和局域网的公有IP？**

==端口映射==

因为这台主机发往百度的数据包到网关路由器的时候，会**把自己的私网地址和端口号映射到一个公网地址和一个端口号**，而且网关会维护这个映射的数据表。当百度的数据包发回来的时候，目的地址和端口号就是出去的时候映射的那组信息，根据这组信息表在上述数据表中对应的内网地址和端口号，进行转发。百度来的数据包并没有主机的mac信息，只有公网地址和端口号。



### NET穿透技术

作用：在某些场景里需要**外网设备主动访问本端内网设备**，但如果本端内网设备没有主动发包，**NAT设备中就不会存在会话**，所以外网设备发过来的包就会被丢弃掉。所以这个时候就需要NAT穿透





### ICMP报文 

> icmp报文头在IP报文头的里面

- **查询类报文应用**  ping  发送回送请求报文   
- **差错类报文应用**  traceroute   
  - **故意设置特定的TTL 来追踪去往目的地时沿途经过的路由器。** 拿到所有路由器IP
  - **故意设置不分片，从而确定路径的 MTU**



> MTU 是数据链路层的限制 但是作用在网络层 所以是 网络层 （加上IP头之后的）数据包不能大于MTU

## ping 127.0.0.1

功能：目的就是检测本机的回路是否正常，如果正常，则说明本机的TCP/IP协议安装正常。如果连这个都不正常，则说明连TCP/IP协议都出了问题，那就需要从系统层面，先修复TCP/IP协议来解决所碰到的网络故障了。



