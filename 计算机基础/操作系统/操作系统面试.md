# 进程管理

## 协程，线程，进程的区别。

详细https://mp.weixin.qq.com/s/vW5n_JWa3I-Qopbx4TmIgQ

- 进程 （PCB管理）

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,**进程是系统进行资源分配和调度的一个独立单位**。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。

- 线程（内核态的TCB）

**线程是进程的一个实体,**是**CPU调度和分派的基本单位,**它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同**属一个进程的其他的线程**==共享进程所拥有的全部资源。==线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

- 协程（用户态的线程 用户态TCB）

**协程是一种用户态的轻量级线程**，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，**直接操作栈则基本没有内核切换的开销**，可以不加锁的访问全局变量，所以上下文的切换非常快。

协程的优势如下：

- **节省 CPU：**避免系统内核级的线程频繁切换，造成的 CPU 资源浪费。好钢用在刀刃上。而协程是用户态的线程，用户可以自行控制协程的创建于销毁，极大程度避免了系统级线程上下文切换造成的资源浪费。
- **节约内存**：在 64 位的Linux中，一个线程需要分配 8MB 栈内存和 64MB 堆内存，系统内存的制约导致我们无法开启更多线程实现高并发。而在协程编程模式下，可以轻松有十几万协程，这是线程无法比拟的。
- **稳定性**：前面提到线程之间通过内存来共享数据，这也导致了一个问题，任何一个线程出错时，进程中的所有线程都会跟着一起崩溃。
- **开发效率**：使用协程在开发程序之中，可以很方便的将一些耗时的IO操作异步化，例如写文件、耗时 IO 请求等。

协程本质上就是用户态下的线程，所以也有人说协程是 “轻线程”，但我们一定要区分用户态和内核态的区别，很关键。



> **内核级线程**阻塞不会导致其他的内核态线程阻塞
>
> **用户态线程**阻塞会导致其他的用户态线程阻塞

> ==Linux系统下==  线程的崩溃会导致进程崩溃



### **对于，线程相比进程能减少开销，体现在：**

- **线程的创建时间比进程快**，因为进程在创建的过程中**，还需要资源管理信息，比如内存管理信息、文件管理信息**，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
- **线程的终止时间比进程快**，因为线程释放的资源相比进程少很多；
- **同一个进程内的线程切换比进程切换快**，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
- 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

所以，不管是时间效率，还是空间效率线程比进程都要高。



## 多线程和多进程的使用场景；什么时候用进程，什么时候用线程；

从性能方面出发，想要更高的性能使用多线程 ，开销低

从安全性出发，使用**多进程**， 一个线程崩溃，对应的进程也会崩溃





## PCB包括哪些

- 进程描述信息：
  - PID进程标识符
  - 用户标识符， 进程归属的用户
- 控制管理信息：
  - 进程当前状态，如 new、ready、running、waiting 或 blocked 等； ==注意PCB通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**==
  - 进程优先级：进程抢占 CPU 时的优先级；
- 资源分配清单：
  - 有关内存地址空间或虚拟地址空间的信息，
  - 所打开文件的列表和所使用的 I/O 设备信息。
- CPU相关信息：
  - CPU的寄存器





## 进程和线程的切换过程

### 进程：

1. 保护现场，保存当前进程的上下文到对应的PCB中，把当前进程的PCB加入相应的队列中
2. 调度到另外一个进程中
3. 恢复现场 读取调度进程的PCB的上下文信息  PC指针指向新进程代码



**其中上下文切换主要包括**

**1.切换新的页表，然后使用新的虚拟地址空间
2.切换内核栈，保存就进程的寄存器和程序计数器，加入新的内容(PCB控制块，资源相关)，硬件上下文切换**

### 线程

##### 内核级线程和用户级线程

同一个进程下的线程共用内存所以不需要切换地址空间

只要进行内核栈的切换，以及上下文的切换

### 僵尸进程和孤儿进程

> 僵尸进程：子进程结束了，但**是父进程没有对其进行释放**（或者说忘记对子进程释放了…）

**危害**

 僵尸进程虽然**不占有任何内存空间**，但如果父进程不调用 wait() / waitpid() 的话，那么保留的信息就不会释放，**其进程号就会一直被占用**，而系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程，此即为僵尸进程的危害。

> 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程(进程号为1)所收养，并由 init 进程对它们完成状态收集工作。

## 进程间通信

## 管道

如果你学过 Linux 命令，那你肯定很熟悉「`|`」这个竖线。

```bash
$ ps auxf | grep mysql
```

上面命令行里的「`|`」竖线就是一个**管道**，它的功能是将前一个命令（`ps auxf`）的输出，作为后一个命令（`grep mysql`）的输入，从这功能描述，可以看出**管道传输数据是单向的**，如果想相互通信，我们需要创建两个管道才行。

同时，我们得知上面这种管道是没有名字，所以「`|`」表示的管道称为**匿名管道**，用完了就销毁。

管道还有另外一个类型是**命名管道**，也被叫做 `FIFO`，因为数据是先进先出的传输方式。

在使用命名管道前，先需要通过 `mkfifo` 命令来创建，并且指定管道名字：

```bash
$ mkfifo myPipe
```

myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：

```bash
$ ls -l
prw-r--r--. 1 root    root         0 Jul 17 02:45 myPipe
```

接下来，我们往 myPipe 这个管道写入数据：

```bash
$ echo "hello" > myPipe  // 将数据写进管道
                         // 停住了 ...
```

你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。

于是，我们执行另外一个命令来读取这个管道里的数据：

```bash
$ cat < myPipe  // 读取管道里的数据
hello
```

可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。

我们可以看出，**管道这种通信方式效率低，不适合进程间频繁地交换数据**。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。

> 那管道如何创建呢，背后原理是什么？

匿名管道的创建，需要通过下面这个系统调用：

```c
int pipe(int fd[2])
```

这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 `fd[0]`，另一个是管道的写入端描述符 `fd[1]`。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/操作系统/进程间通信/5-管道-pipe.jpg)

其实，**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。

看到这，你可能会有疑问了，这两个描述符都是在一个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程的呢？

我们可以使用 `fork` 创建子进程，**创建的子进程会复制父进程的文件描述符**，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/操作系统/进程间通信/6-管道-pipe-fork.jpg)

管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：

- 父进程关闭读取的 fd[0]，只保留写入的 fd[1]；
- 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/操作系统/进程间通信/7-管道-pipe-fork-单向通信.jpg)

所以说如果需要双向通信，则应该创建两个管道。

到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。

在 shell 里面执行 `A | B`命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/操作系统/进程间通信/8-管道-pipe-shell.jpg)

所以说，在 shell 里通过「`|`」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。

我们可以得知，**对于匿名管道，它的通信范围是存在父子关系的进程**。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。

另外，**对于命名管道，它可以在不相关的进程间也能相互通信**。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。

不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作

#### 

#### **两者的异同**

不同点：

- 匿名只能在 有亲缘关系的进程间通信，有名的都可以
- 匿名的不存在于文件系统中
- 匿名管道（类似有缓存区的channel）
  - ![image-20220529222730271](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220529222730271.png)
- 命名管道（类似无缓存区的channel）
  - 一个为只读而打开一个管道的进程会阻塞，直到另外一个进程为只写打开管道；
  - 一个为只写而打开一个管道的进程会阻塞，直到另外一个进程为只读打开管道。

相同点：

- 先进先出
- 单向通信
- 



消息队列

共享内存

信号量

信号

套接字（Socket）



## 进程的状态

五状态模型和七状态模型

### 挂起

- 理解一：**挂起是一种主动行为**，因此恢复也应该要主动完成，**而阻塞则是一种被动行为**，是在等待事件或资源时任务的表现，你不知道他什么时候被阻塞(pend)，也就不能确切 的知道他什么时候恢复阻塞。而且挂起队列在操作系统里可以看成一个，而阻塞队列则是不同的事件或资源（如信号量）就有自己的队列。
- 理解二：阻塞（pend）就是任务释放CPU，其他任务可以运行，一般在等待某种资源或信号量的时候出现。挂起（suspend）不释放CPU，如果任务优先级高就永远轮不到其他任务运行，一般挂起用于程序调试中的条件中断，当出现某个条件的情况下挂起，然后进行单步调试。
- 理解三：pend是task主动去等一个事件,或消息.suspend是直接悬挂task,以后这个task和你没任何关系,任何task间的通信或者同步都和这个suspended task没任何关系了,除非你resume task;
- 理解四：任务调度是操作系统来实现的，任务调度时，直接忽略挂起状态的任务，但是会顾及处于pend下的任务，当pend下的任务等待的资源就绪后，就可以转为ready了。ready只需要等待CPU时间，当然，任务调度也占用开销，但是不大，可以忽略。可以这样理解，只要是挂起状态，操作系统就不在管理这个任务了。
- 理解五：挂起是主动的，一般需要用挂起函数进行操作，若没有resume的动作，则此任务一直不会ready。而阻塞是因为资源被其他任务抢占而处于休眠态。两者的表现方式都是从就绪态里“清掉”，即对应标志位清零，只不过实现方式不一样。

==挂起是主动的，恢复也需要主动，而阻塞是被动的，挂起后进程不占用内存==

==挂起可能释放CPU，可能不释放==

## 死锁 

### 什么是死锁

在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。

### 死锁的必要条件

- **互斥**：一个资源一次只能被一个进程使用；
- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；
- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；
- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。

### 死锁的处理方法

1. **直接忽略：**因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。
2. **死锁预防：破坏四个必要条件**
   - 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；
   - 破坏占有并等待条件：
     - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；
     - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；
     - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；
   - 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；
   - 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。
3. **死锁避免**：  ==银行家算法==     指分配资源之前先确定资源分配是否会造成系统死锁。如果会死锁，则不分配，只有确认不会死锁后才进行分配。
   1. 最常见的并且可行的就是**使用资源有序分配法，来破环环路等待条件**。
4. **死锁解除**
   1. 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；
   2. 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；
   3. 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。

### 死锁的排查

- go语言中，可以通过pprof工具去查看程序在哪里卡住了，
- 再去查看这个锁在哪些地方获取到了，去查看这些获取锁的地方是否存在没有释放锁的情况，
- **什么样的逻辑可能卡住？**
  1. 可能是**一个rpc调用**，或者**一个http调用**，你没有设置超时时间，而和远端的交互又出了问题，一直拿不到回复
  2. 可能是在读写数据库，这时也有可能会由于数据量太大或者sql写的不够好或者和数据库之间的连接出现了问题，导致卡很久



1、撤消陷于死锁的全部进程；2、逐个撤消陷于死锁的进程，直到死锁不存在；3、从陷于死锁的进程中逐个强迫放弃所占用的资源，直至死锁消失

- 



### 锁（互斥锁和自旋锁）

- **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；
- **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；

### 互斥锁的缺点

互斥锁加锁失败时，会从**用户态陷入到内核态**，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。

那这个开销成本是什么呢？会有**两次线程上下文切换的成本**：

- 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
- 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。

### 自旋锁

自旋锁是通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

一般加锁的过程，包含两个步骤：

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；

> 所以，**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**



## 写时复制

 详细见： [写时复制](D:\Coding\笔记\计算机基础\操作系统\写时复制.md)

fork出的子进程共享父进程的物理空间，当父子进程有内存写入操作时，read-only内存页发生中断，将触发的异常的内存页复制一份(其余的页还是共享父进程的)。

**优点：**

COW技术可减少分配和复制大量资源时带来的瞬间延时。
COW技术可减少不必要的资源分配。比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。

**缺点**

如果在fork()之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断page-fault)，这样就得不偿失。
几句话总结Linux的Copy On Write技术：





## 用户态和核心态的概念

- **用户态**：

内核态与用户态是操作系统的两种运行级别,当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；

- **核心态：**

当程序运行在0级特权级上时，就可以称之为运行在内核态。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。

==两种状态的主要区别==

处于用户态执行时，**进程所能访问的内存空间和对象受到限制**，其所处于占有的处理机是可被抢占的 ； 而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是不允许被抢占的。

==为啥要区别==

是为了区别执行 **特权指令 与非特权指令**

在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。如果所有的程序都能使用这些指令，那么你的系统一天死机n回就不足为奇了。所以，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。 

 

### 两者之间如何切换

1.  **系统调用**


这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如fork()实际上就是执行了一个创建新进程的系统调用。**而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现**，例如Linux的int 80h中断。

2. **中断**


当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 

3. **异常**


当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 



# 内存管理

## 虚拟内存

虚拟内存是一种内存管理技术

**虚拟内存：使程序认为它拥有==连续的可用的内存==（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。**

主要是由于程序具有局部性，某一时间占用的内存很小，虚拟内存利用硬盘存储，只把需要运行的内存，真正的放到内存空间中，将不用的换出（**页面置换算法**）

虚拟内存可以使程序的内存大于实际的物理内存

- 作用：
  - 达到扩充内存的效果（磁盘）
  - 使进程各个进程的内存相互独立（映射关系）



1.**每个进程都有各自独立的4G 字节的虚拟地址空间**。4G的进程空间分为两部分，**0~3G-1 为用户空间**，3G~ **4G-1 为内核空间。**
2.用户程序中使用的都是虚拟地址空间中的地址，永远无法直接访问实际物理地址。
3.**虚拟内存到物理内存的映射由操作系统动态维护**。
4.虚拟内存一方面保护了操作系统的安全，另一方面允许应用程序使用比实际物理内存更大的地址空间。
5.用户空间中的代码不能直接访问内核空间中的代码和数据，但是可以通过系统调用进入内核态，间接地与内核交互。 
6.对内存的越权访问，或访问未建立映射的虚拟内存（野指针、不在映射表中），将会导致段错误。

7. 用户空间对应进程，进程一切换，用户空间随即变换。
   内核空间由操作系统内核使用，不会随进程切换而变化。
   内核空间由内核根据独立且唯一的页表init_mm.pgd 进行映射，而用户空间的页表则每个进程一份。

8. 每个进程的内存空间完全独立，因此在不同进程之间交换虚拟地址毫无意义。
9. 虚拟内存到物理内存的映射，以页（4096字节）为单位

#### ==虚拟内存是利用硬盘（磁盘）实现的==



## 进程的虚拟内存分布长什么样

主要分为用户空间和内核空间

- 进程在用户态时，只能访问用户空间内存；
- 只有进入内核态后，才可以访问内核空间的内存；

![image-20220726105505483](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220726105505.png)

虽然每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是==相同的物理内存==**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。

![image-20220726105630744](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220726105630.png)

### 分布图

**分布的情况，以 32 位系统为例，**

![image-20220726110302058](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220726110302.png)

### 用户空间

通过这张图你可以看到，用户空间内存，从**低到高**分别是 6 种不同的内存段：

- **程序文件段（.text）**，包括二进制可执行代码；
- **已初始化数据段（.data**），包括静态常量；
- **未初始化数据段（.bss**），包括未初始化的静态变量；
- **堆段**，包括动态分配的内存，从低地址开始向上增长；
- **文件映射段**，包括动态库、共享内存等，从低地址开始向上增长（[跟硬件和内核版本有关 (opens new window)](http://lishiwen4.github.io/linux/linux-process-memory-location)）；
- **栈段**，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 `malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存

### 内核空间

- **内核代码段**，存放内核的代码和数据，所有进程的内核代码段都映射到同样的物理内存，并在内存中**持续存在**
- **与进程有关的数据结构段**，存放进程都各自的[PCB](https://www.cnblogs.com/Joezzz/p/9623718.html)和[页表](https://www.cnblogs.com/Joezzz/p/9798899.html)，并映射到不同的物理内存







## 内存分页和分段

### 页表

页表包含的字段有：

![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220701070957.png)

## 物理内存和虚拟内存怎么进行映射



![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220701071035.png)

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

### **一级页表**：

- 页表地址转换，把一个内存地址分成**页号(Directory)** 和**偏移量(Offset)** 两个部分。以一个 32 位的内存地址，页的大小 4KB 为例，内存地址的 20 位的高位表示页号，12 位（212 = 4KB）的低位表示偏移量。**时间复杂度O（1）**
- ![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/20210615160828145.png)

**缺点：**使用一级页表，需要==连续的内存空间==来存放所有的页表项，比如虚拟地址空间大小为4G，每个页大小依然为4K，如果使用一级页表的话，共有2^20个页表项，如果每一个页表项占4B，那么存放所有页表项需要4M，为了能够随机访问，那么就需要连续4M的内存空间来存放所有的页表项。随着虚拟地址空间的增大，存放页表所需要的连续空间也会增大。

### 多级页表：

- 类似b+树   **几级页表就要几次查询  时间换空间**

**优势：**

1.可以离散存储页表。

2.在某种意义上节省页表内存空间。

**劣势：**

增加寻址次数，从而延长访存时间。

### TLB：

我们可以把 TLB 简化成存储着**键值对的哈希表**。类似于给页表加入了缓存，只有当缓存没有的时候才会去查页表。   ==**我们在CPU上提供一个TLB，这个TLB是由相关存储器实现的，由于其靠近CPU**，速度很快，所以访存速度一定程度上得到了减少==







## 64 位和32 位 CPU的区别 

> 64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？

64 位相比 32 位 CPU 的优势主要体现在两个方面：

- 64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以**只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大**。
- 64 位 CPU 可以**寻址更大的内存空间**，32 位 CPU 最大的寻址地址是 4G，即使你加了 8G 大小的内存，也还是只能寻址到 4G，而 64 位 CPU 最大寻址地址是 `2^64`，远超于 32 位 CPU 最大寻址地址的 `2^32`。



## CPU的执行速度

1. 寄存器
2. CPU高速缓存
   1. 一级缓存
   2. 二级缓存
   3. 三级缓存
3. 内存
4. 硬盘

![image-20220516220753312](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//imgsimage-20220516220753312.png)

![image-20220516221031732](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//imgsimage-20220516221031732.png)



## page cache

> 是对磁盘文件的缓存，注意与CPU cache的区别

#### Page Cache 与预读

Page Cache具有预读机制

一个例子是：

- 用户线程仅仅请求读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
- 但是操作系统出于局部性原理会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；

#### 一致性

写回和写穿

当前 Linux 下以两种方式实现文件一致性：

1. **Write Through（写穿）**：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；
2. **Write back（写回）**：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；

### Page Cache 的优势

1. 加快数据的访问（**缓存最近的数据**）

   1. 如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I/O 了，直接命中内存缓存即可。

      由于内存访问比磁盘访问快很多，因此加快数据访问是 Page Cache 的一大优势。

2. 减少IO次数，提高系统磁盘吞吐量（**预读功能**）

   1. 得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I/O 将多个 page 装入 Page Cache 能够减少磁盘 I/O 次数， 进而提高系统磁盘 I/O 吞吐量。

### Page Cache 的劣势

page cache 也有其劣势，最直接的缺点是==需要占用额外物理内存空间==，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。（传输大文件时应该使用直接IO  Direct I/O）

**Direct I/O 的读写非常有特点**：

- Write 操作：由于其不使用 page cache，所以其进行写文件，如果返回成功，数据就真的落盘了（不考虑磁盘自带的缓存）；
- Read 操作：由于其不使用 page cache，每次读操作是真的从磁盘中读取，不会从文件系统的缓存中读取。



### page cache  和CPU cache的区别

- 一个是磁盘的缓存  以页 （4KB）为单位读取
- 一个是内存的缓存 以**Cache Line**（默认64字节）为单位

# 网络编程

### Socket编程

基于tcp的

![image-20220529213059133](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220529213059133.png)

**步骤**：

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

基于UDP的

<img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220529212811389.png" alt="image-20220529212811389" style="zoom: 67%;" />

### 阻塞和非阻塞

- 阻塞和非阻塞的区别

  - 阻塞：为了完成一个功能,发起一个调用,**如果不具备条件的话（数据没准备好）则将当前线程挂起一直等待,直到具备条件则完成**

  - 非阻塞：为了完成一个功能,发起一个调用,**具备条件直接输出,不具备条件直接报错返回** 需要多次发起，第n次满足条件（数据准备好了）的时候==，**线程依然会被挂起**==

  - > 阻塞是不占用CPU的 因为线程会挂起，CPU可以执行其他的线程

### 同步和异步

同步和异步描述的是消息通信的机制。

**同步**

当一个request发送出去以后，会得到一个response，这整个过程就是一个同步调用的过程。哪怕response为空，或者response的返回特别快，但是针对这一次请求而言就是一个同步的调用。

**异步**

当一个request发送出去以后，没有得到想要的response，而是通过后面的callback、状态或者通知的方式获得结果。可以这么理解，对于异步请求分两步：

1）调用方发送request没有返回对应的response（可能是一个空的response）；

2）服务提供方将response处理完成以后通过callback的方式通知调用方。

对于1）而言是同步操作（调用方请求服务方），对于2）而言也是同步操作（服务方回掉调用方）。从请求的目的（调用方发送一个request，希望获得对应的response）来看，这两个步骤拆分开来没有任何意义，需要结合起来看，而这整个过程就是一次异步请求。异步请求有一个最典型的特点：需要callback、状态或者通知的方式来告知调用方结果。

**总结**

- 同步和异步就看调用方是否需要通过callback、通知或者状态来获取结果
- 阻塞和非阻塞就看调用方在发送请求后是否block住了

或者说：

- 阻塞和非阻塞是数据没有准备好时，线程时阻塞等待，还是直接返回，之后再来询问
- 同步和异步是：当数据准备好了，进行拷贝的时候，是要等待他返回，还是直接返回，拷贝（处理）完成之后，系统通知你



### 阻塞socket 和非阻塞socket

- send
  - 阻塞：当socket的发送缓存区没有值时会一直阻塞
  - 非阻塞：直接返回错误

- recvfrom
  - 阻塞：当socket的接收缓存区没有值时会一直阻塞
  - 非阻塞：直接返回错误



### 五种I/O模型

- #### 阻塞IO

- #### 非阻塞IO

- #### 多路复用IO

- #### 信号驱动型IO

  - 调用read之后，数据没准备好 继续做自己的事       当数据准备好了，会使用信号通知调用方，数据准备好了，可以来读取了,把数据从内核态拷贝到用户态

- #### 异步IO

  - 调用read之后，不需要管任何事情，内核线程会读取（内核态拷贝到用户态）完数据之后，再来通知他，已经读取完了

  - > 这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们**合适可以开始下一个IO操作**，而异步IO模型是由内核通知我们操作**什么时候完成**。





## select 、poll和epoll的区别：

#### select

select 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 `1024`，只能监听 0~1023 的文件描述符。

poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

但是 poll 和 select 并没有太大的本质区别，**都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**，这种方式随着并发数上来，性能的损耗会呈指数级增长

 **select的几大缺点：**

**（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大**

**（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大**

**（3）select支持的文件描述符数量太小了，默认是1024**

#### Epoll

![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/epoll.png)

> - 在内核采用了红黑树的数据结构，插入查询删除都是 log（N）
> - 将有事件发生的Socket存入一个双向链表rdllist中，只需要遍历链表就ok，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。
> - epoll只需要将链表中的socket从内核态拷贝进入用户态即可

epoll支持两种触发模式：分别是**边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）**。

- 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
- 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取；



### 内核是如何监控哪个Socket有事件发生的

将对应的线程全部加入到socket的等待队列中，对应的socket中的缓冲区中有值的话，唤醒等待队列中的线程，将其重新加入到运行队列中等待CPU执行



### 什么时候使用select/poll、什么时候用epoll

- 当**连接数较多并且有很多的不活跃连接**时，epoll的效率比其它两者高很多；
- 但是**当连接数较少并且都十分活跃的情况**下，由于epoll需要很多回调，因此性能可能低于其它两者



## 零拷贝 

最原始的read+ write

<img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220714101837.png" alt="img" style="zoom:80%;" />



期间共**发生了 4 次用户态与内核态的上下文切换，发生了 4 次数据拷贝**

### 第一种零拷贝

> 使用mmp代替read

`mmap()` 系统调用函数会直接把内核缓冲区里的数据「**映射**」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。

- **发生了 4 次用户态与内核态的上下文切换，发生了 3次数据拷贝** ==减少了一次数据拷贝==

- 只是不需要通过拷贝的方式 让用户进程得到 数据

<img src="https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220714102308.png" alt="image-20220714102308291" style="zoom:80%;" />



### 第二种

> sendfile 代替read 和write

#### 在 Linux 内核版本 2.1 中，

提供了一个专门发送文件的系统调用函数 `sendfile()`

- 只有 2 次上下文切换，和 3 次数据拷贝

![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220714102704.png)



#### 从 Linux 内核 `2.4` 版本开始起

网卡支持 SG-DMA 技术的情况下，我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。



- 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
- 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；

![img](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220714102716.png)

**使用sendfile  和mmap**

优点：不需要CPU参与

缺点：在处理大文件的时候反而会因为每次复制到缓存区而浪费开销



# 文件系统

## 文件描述符

> 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，==指向内核为每一个进程所维护的该进程打开文件的记录表==。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。

对于控制台（Console）的[标准输入](https://zh.wikipedia.org/wiki/标准输入)，[标准输出](https://zh.wikipedia.org/wiki/标准输出)，[标准错误输出](https://zh.wikipedia.org/wiki/标准错误输出)也对应了三个文件描述符。它们分别是0,1,2

- 每个文件描述符会与一个打开的文件相对应
- 不同的文件描述符也可能指向同一个文件
- 相同的文件可以被不同的进程打开，也可以在同一个进程被多次打开

### 文件描述符的生成

- open(), open64(), creat(), creat64()
- socket()
- socketpair()
- pipe()



#### 系统为维护文件描述符，建立了三个表

- 进程级的文件描述符表
- 系统级的文件描述符表
- 文件系统的i-node表

![image-20220711122454893](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//img/20220711122502.png)

## inode（索引节点）

索引节点，也就是 *inode*，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、**数据在磁盘的位置**等等。索引节点是文件的**唯一**标识，它们之间一一对应，也同样都会被存储在硬盘中，所以**索引节点同样占用磁盘空间**。

## 硬链接

> 多个文件名指向同一个inode号码。

这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。

## 软链接

软链接相当于重新创建一个文件，这个文件有**独立的 inode**，但是这个**文件的内容是另外一个文件的路径**，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以**软链接是可以跨文件系统的**，甚至**目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。**==类似快捷方式==

#### 总结硬链接和软连接的区别：

1硬链接不能创建目录和跨文件系统创建，软连接可以对目录和跨分区。

2每增加一次硬链接创建，其links次数便会增加一次，其inode相同。而软连接是指向另一个文件路径，其大小指向的路径字符串的长度，不会增加减少目标inode的引用计数，其inode不同。

3删除文件的硬连接的时候，对原文件不会影响，但如果原文件没有了硬连接，那么会导致文件删除。

4删除软连接的原文件的话，会导致连接指向失败。



# 设备管理

### 键盘敲入A字母，操作系统会发生什么

![image-20220608202233997](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img//imgs/image-20220608202233997.png)





那当用户输入了键盘字符，**键盘控制器**就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送**中断请求**。

CPU 收到中断请求后，操作系统会**保存被中断进程的 CPU 上下文**，然后调用键盘的**中断处理程序**。

键盘的中断处理程序是在**键盘驱动程序**初始化时注册的，那键盘**中断处理函数**的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。

得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。

显示出结果后，**恢复被中断进程的上下文**。

# Linux

> Linux 文件系统相关，inode结构，软硬连接，以及文件描述符是什么，怎么去修改，最多允许多少？
> Linux 读写数据的整个流程，内核状态切换；Mmap(内存映射)和sendFile函数零拷贝什么原理？
> Linux是内存管理是怎么样的？虚存是什么，虚拟地址->物理地址的整个流程是什么？
> Linux说一说fork这个函数，返回什么；父子进程之间资源是共享的的吗？父子进程之间怎么用匿名管道通信？
> 父进程死掉子进程会怎么样？子进程挂掉父进程呢？知道僵尸进程吗，Linux会怎么处理？



## 内存分配

> 分配的全部是虚拟内存

### malloc() 分配的是物理内存吗？

不是的，**malloc() 分配的是虚拟内存**。

如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系

**malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。**

- 方式一：通过 brk() 系统调用从堆分配内存  **分配小于128k**
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存；**分配大于128k**

### brk

![image-20220530223746131](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220530223746131.png)

### mmap（）

方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：

![image-20220530223946792](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/image-20220530223946792.png)



### free 释放内存，会归还给操作系统吗？

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**

## 为什么不全部使用 mmap 来分配内存？

因为向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。

所以，申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用。

另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。

也就是说，**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。

为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。

**等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗**。

## 既然 brk 那么牛逼，为什么不全部使用 brk 来分配？

前面我们提到通过 brk 从堆空间分配的内存，并不会归还给操作系统，那么我们那考虑这样一个场景。

如果我们连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。

![图片](https://cdn.jsdelivr.net/gh/Jason-Wu-1999/blog.img/imgs/75edee0cb75450e7987a8a482b975bda.png)

但是如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。

因此，随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

所以，malloc 实现中，充分考虑了 sbrk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。





## Linux 进程的内存分布长什么样？

在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：

![图片](https://img-blog.csdnimg.cn/img_convert/1db038e1d2e5325b05e2bb80475d962a.png)

通过这里可以看出：

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

再来说说，内核空间与用户空间的区别：

- 进程在用户态时，只能访问用户空间内存；
- 只有进入内核态后，才可以访问内核空间的内存；

虽然每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。

![图片](https://img-blog.csdnimg.cn/img_convert/c88bda5db60029f3ea57e4306e7da936.png)

接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。

我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：

通过这张图你可以看到，用户空间内存从**低到高**分别是 6 种不同的内存段：

![图片](https://img-blog.csdnimg.cn/img_convert/7b5b6b3728acde8df019350df3cb85c1.png)

- 程序文件段，包括二进制可执行代码；
- 已初始化数据段，包括静态常量；
- 未初始化数据段，包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 ）；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

在这 6 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 `malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存



## Linux统计文件有多少行数据

- ​	wc -l filename 就是查看文件里有多少行
- ​    wc -w filename 看文件里有多少个word。
- ​    wc -L filename 文件里最长的那一行是多少个字。

###  sed -n '70,75p' date.log       输出第70行到第75行的内容

- chmod修改文件权限
- chown用于设置文件所有者和文件关联组的命令。



### 查看文件

- cat ： 一次加载全部的文件 ，对于大文件慎用
- less ： 分页查看 不会加载整个文件，适合大文件
- head  -n  fliename： 查看开始 n 行
- tail -n  fliename : 查看末尾 n 行

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。



### **查找进程使用的所有文件描述符**

首先查找进程对应的进程ID号

```
ps -ef |grep xxx
```

获取进程id占用的所有文件描述符命令:

```
ls -l /proc/$process_id/fd
```


其中$process_id需要替换为自己要查询的实际进程id，但是ls出来的是一行一行的，不能统计描述符号数量，因此使用wc进行统计:

```
ls -l /proc/$process_id/fd | wc -l
```

