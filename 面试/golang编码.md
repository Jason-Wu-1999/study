## go中的字符本质

在go语言中，字符存储原理：

- 存储：字符->对应编码unicode->二进制
- 读取：二进制->unicode编码->字符

Unicode 和 UTF-8 的概念是一个非常基础和重要，但是却容易被忽略的问题。

## 字符集

在计算机系统中，所有的数据都以二进制存储，所有的运算也以二进制表示，人类语言和符号也需要转化成二进制的形式，才能存储在计算机中，于是需要有一个从人类语言到二进制编码的映射表。这个映射表就叫做字符集。

## ASCII

最早的字符集叫 American Standard Code for Information Interchange（美国信息交换标准代码），简称 ASCII，由 American National Standard Institute（美国国家标准协会）制定。在ASCII 字符集中，字母 A 对应的字符编码是 65，转换成二进制是 0100 0001，由于二进制表示比较长，通常使用十六进制 41。

## GB2312、GBK

ASCII 字符集总共规定了 128 种字符规范，但是并没有涵盖西文字母之外的字符，当需要计算机显示存储中文的时候，就需要一种对中文进行编码的字符集，GB 2312 就是解决中文编码的字符集，由国家标准委员会发布。同时考虑到中文语境中往往也需要使用西文字母，GB 2312 也实现了对 ASCII 的向下兼容，原理是西文字母使用和 ASCII 中相同的代码，但是 GB 2312 只涵盖了 6000 多个汉字，还有很多没有包含在其中，所以又出现了 GBK 和 GB 18030，两种字符集都是在 GB 2312 的基础上进行了扩展。

## Unicode

可以看到，光是简体中文，就先后出现了至少三种字符集，繁体中文方面也有 BIG5 等字符集，几乎每种语言都需要有一个自己的字符集，每个字符集使用了自己的编码规则，往往互不兼容。同一个字符在不同字符集下的字符代码不同，这使得跨语言交流的过程中双方必须要使用相同的字符编码才能不出现乱码的情况。为了解决传统字符编码的局限性，Unicode 诞生了，Unicoide 的全称是 Universal Multiple-Octet Coded Character Set（通用多八位字符集，简称 UCS）。Unicode 在一个字符集中包含了世界上所有文字和符号，统一编码，来终结不同编码产生乱码的问题。

## 字符编码 UTF-8

Unicode 统一了所有字符的编码，是一个 Character Set，也就是字符集，字符集只是给所有的字符一个唯一编号，但是却没有规定如何存储，一个编号为 65 的字符，只需要一个字节就可以存下，但是编号 40657 的字符需要两个字节的空间才可以装下，而更靠后的字符可能会需要三个甚至四个字节的空间。

这时，用什么规则存储 Unicode 字符就成了关键，我们可以规定，一个字符使用四个字节存储，也就是 32 位，这样就能涵盖现有 Unicode 包含的所有字符，这种编码方式叫做 UTF-32（UTF 是 UCS Transformation Format 的缩写）。UTF-32 的规则虽然简单，但是缺陷也很明显，假设使用 UTF-32 和 ASCII 分别对一个只有西文字母的文档编码，前者需要花费的空间是后者的四倍（ASCII 每个字符只需要一个字节存储）。

在存储和网络传输中，通常使用更为节省空间的变长编码方式 UTF-8，UTF-8 代表 8 位一组表示 Unicode 字符的格式，使用 1 - 4 个字节来表示字符。

**UTF-8 的编码规则如下**（U+ 后面的数字代表 Unicode 字符代码）：

U+ 0000 ~ U+ 007F: 0XXXXXXX
U+ 0080 ~ U+ 07FF: 110XXXXX 10XXXXXX
U+ 0800 ~ U+ FFFF: 1110XXXX 10XXXXXX 10XXXXXX
U+10000 ~ U+1FFFF: 11110XXX 10XXXXXX 10XXXXXX 10XXXXXX
可以看到，UTF-8 通过开头的标志位位数实现了变长。对于单字节字符，只占用一个字节，实现了向下兼容 ASCII，并且能和 UTF-32 一样，包含 Unicode 中的所有字符，又能有效减少存储传输过程中占用的空间。





## `Unicode`和字符编码

在介绍`rune`类型之前，我们还是要从一些基础知识开始。------ `Unicode`和字符编码。

- 什么是`Unicode`？

我们都知道计算机只能处理数字，如果想要处理文本需要转换为数字才能处理，早些时候，计算机在设计上采用`8bit`作为一个`byte`，一个`byte`表示的最大整数就是`255`，想表示更大的整数，就需要更多的`byte`。显然，一个字节表示中文，是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，我国制定了`GB2312`编码，用来把中文编进去。但是世界上有很多语言，不同语言制定一个编码，就会不可避免地出现冲突，所以`unicode`字符就是来解决这个痛点的。`Unicode`把所有语言都统一到一套编码里。总结来说："**unicode其实就是对字符的一种编码方式，可以理解为一个字符---数字的映射机制，利用一个数字即可表示一个字符。**

- 什么是字符编码？

虽然`unicode`把所有语言统一到一套编码里了，但是他却没有规定字符对应的二进制码是如何存储。以汉字“汉”为例，它的 `Unicode` 码点是 `0x6c49`，对应的二进制数是 `110110001001001`，二进制数有 `15`位，这也就说明了它至少需要 `2`个字节来表示。可以想象，在`Unicode` 字典中往后的字符可能就需要 `3`个字节或者 `4`个字节，甚至更多字节来表示了。

这就导致了一些问题，计算机怎么知道你这个`2`个字节表示的是一个字符，而不是分别表示两个字符呢？这里我们可能会想到，那就取个最大的，假如 `Unicode`中最大的字符用`4` 字节就可以表示了，那么我们就将所有的字符都用`4`个字节来表示，不够的就往前面补`0`。这样确实可以解决编码问题，但是却造成了空间的极大浪费，如果是一个英文文档，那文件大小就大出了`3` 倍，这显然是无法接受的。

于是，为了较好的解决`Unicode` 的编码问题， `UTF-8` 和`UTF-16` 两种当前比较流行的编码方式诞生了。`UTF-8` 是目前互联网上使用最广泛的一种`Unicode`编码方式，它的最大特点就是可变长。它可以使用 `1 - 4`个字节表示一个字符，根据字符的不同变换长度。

==在`UTF-8`编码中，====一个英文为一个字节，一个中文为三个字节。==

## 例子

```go
func main()  {
 str := "jason杰森"
 fmt.Println(len(str))
 fmt.Println(len([]rune(str)))
}
```

```
输出：
11
7
```

### 乱码问题

注意在截取string的时候注意可能会导致乱码问题

因为知道一个汉字是3个字节，如果截取中文string时候不是按照3的倍数截取就会导致乱码问题

例如

```
import "fmt"
func main()  {
   str := "乱码问题测试"
   fmt.Println(str)
   fmt.Println(str[:5])
}

------------------
输出：
乱码问题测试
乱�

```

#### 解决方法

转化为字符，按字符个数截取

```
package main

import "fmt"
func main()  {
	str := "乱码问题测试"
	fmt.Println(str)
	fmt.Println(str[:5])

	str2:= []rune(str)
	fmt.Println(len(str2))
	fmt.Println(string(str2[:2]))

}

--------------------
乱码问题测试
乱�
6
乱码
```



